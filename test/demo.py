import unicodedata
import os
import collections

from logzero import logger

from ZiCutter.ZiCutter import ZiCutter 
import UnicodeTokenizer


def get_langs():
    alphabet = ''.join(chr(x) for x in range(ord('a'), ord('z')+1))
    langs = [x+y for x in alphabet for y in alphabet]
    return langs


def char_name(x, tokenizer):
    try:
        name = unicodedata.name(x)
        # words = tokenizer.tokenize(name)
        words = name.split(' ')
        return words
    except Exception as e:
        return []


def count_name():
    tokenizer = UnicodeTokenizer.UnicodeTokenizer()
    freq = collections.Counter()
    for i in range(0x110000):
        words = char_name(chr(i), tokenizer)
        if not words:
            continue
        x = words[-1][-2:].lstrip('-').lower()
        freq[x] += 1
    words = [(k, v) for k, v in freq.items()]
    words.sort(key=lambda x: -x[1])
    with open("name_tail_freq.txt", "w")as f:
        for k, v in words:
            f.write(f'{k}\t{v}\n')
    logger.info(freq)


def char_name_first(x):
    try:
        name = unicodedata.name(x)
        words = name.split(' ')
        return words[0]
    except Exception as e:
        logger.error(x)
        catg = unicodedata.category(x)
        return catg


def test_first(dir):
    p = dir+'/word_frequency.tsv'
    if not os.path.exists(p):
        return
    logger.info(p)
    store = collections.Counter()
    for l in open(p):
        t = l.split('\t')[0]
        if not t:
            continue
        names = [char_name_first(x) for x in t]
        if len(set(names)) > 1:
            logger.error((l, names))
        store[names[0]] += 1
    # logger.info(store)
    return store

def count_first():
    freq=collections.Counter()
    langs = get_langs()
    for lang in langs:
        # dir = f"C:/data/lang/{lang}"
        dir = f"C:/data/languages/{lang}"
        # test_lang(dir)
        c=test_first(dir)
        if c:
            freq|=c
    words = [(k, v) for k, v in freq.items()]
    words.sort(key=lambda x: -x[1])
    with open("name_first_freq.txt", "w")as f:
        for k, v in words:
            f.write(f'{k}\t{v}\n')
    logger.info(freq)



def test_module():
    from ZiCutter import ZiCutter

    print(ZiCutter.Bigrams, len(ZiCutter.Bigrams))  # 1358
    print(ZiCutter.GouJian, len(ZiCutter.GouJian))  # 2365


def test_lang(dir):

    # build
    cutter = ZiCutter(dir=dir)
    cutter.build()

    # use
    cutter = ZiCutter(dir=dir)
    line = "Ô°ø'„Äá„é°[‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏û‡∏¥‡∏ò‡∏µ‡πÅ‡∏ï‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏£‡∏Ñ‡∏∞‡∏±‡∏µ‡∏¥‡πå‡∏∑‡πá‡πç‡∏∂]‚Ößpays-g[ran]d-blanc-√©lev√© ¬ª (ÁôΩÈ´òÂ§ßÂ§èÂúã)ÁÜµüòÄ'\x0000ÁÜá"
    print(cutter.tokenize(line))


if __name__ == "__main__":
    # count_name()
    # count_first()
    # test_module()

    langs = ["", 'sw', 'ur', 'ar', 'en', 'fr',
             'ja', 'ru', 'zh', 'th', 'global']
    langs = get_langs()

    for lang in langs:
        # dir = f"C:/data/lang/{lang}"
        dir = f"C:/data/languages/{lang}"
        test_lang(dir)
        # test_first(dir)
        # break


"""
[I 220710 00:27:38 ZiCutter:105] C:/data/languages/global\JiZi.txt load  JiZi:1719
[I 220710 00:27:39 ZiCutter:55]   C:/data/languages/global\HeZi.txt JiZi:3727 --> loadHeZi 92463  values:1041
[I 220710 00:27:39 ZiCutter:109] C:/data/languages/global\HeZi.txt HeZi:92463 values:1041
[I 220710 00:27:39 ZiCutter:112] C:/data/languages/global loaded vocab:3727
[I 220710 00:27:39 ZiCutter:115]  C:/data/languages/global building
[I 220710 00:27:39 ZiCutter:120] vocab:3727 JiZi:1755
[I 220710 00:27:39 He2Zi:122] JiZi:1755 ChaiZi:94235 YiTiZi:27440
[I 220710 00:27:41 He2Zi:70] epoch:0 base:11264 --> 3216 
[I 220710 00:27:41 He2Zi:70] epoch:1 base:3216 --> 1959 
[I 220710 00:27:42 He2Zi:70] epoch:2 base:1959 --> 1944 
[I 220710 00:27:42 He2Zi:70] epoch:3 base:1944 --> 1944 
[I 220710 00:27:42 He2Zi:70] epoch:4 base:1944 --> 1837 
[I 220710 00:27:43 He2Zi:70] epoch:5 base:1837 --> 1829 
[I 220710 00:27:43 He2Zi:70] epoch:6 base:1829 --> 1828 
[I 220710 00:27:44 He2Zi:70] epoch:7 base:1828 --> 1828 
[I 220710 00:27:44 He2Zi:104] giveup:246 „¢ø„§ô„¨ã„Æ¢„Øõ‰Çâ‰í≠‰óî‰ôà‰ûÄ‰´õ‰≥ß‰æØÂÄôÂá´ÂèèÂñâÂõôÂ††Â£∫Â¨ùÂ¨ΩÂ≤õÂ≥∂Â∏øÊç£ÊêóÊû≠Ê¢üÊßùÁå¥ÁòäÁù∫ÁØåÁ≥áÁ∑±ÁºëÁø≠ËëîËüÇË¢ÖË£äÈÑáÈÑ°Èç≠È§±ÈØ∏Ô•ßÔ¶ÅÔ®©Ô™û†Ñè†á°†âÄ†ã´†çã†éñ†ê≤†ëº†íé†ñÅ†ó¶†ù∑†©≥
†™ï†¨´†≥ß°ÄÆ°Ü¢°ã¨°è≠°êù°ë©°ïè°ñ£°óÅ°ôû°öá°üë°†ø°≠≥°∑ä°πµ°ªÖ¢Ü¥¢á≠¢â∫¢âª¢äá¢ãµ¢ç¥¢èª¢úµ¢¶ò¢∞°¢≥ö£Ä®£Ä¥£òñ£öù£ùÑ££†£§ù£§º£•í£πã£ª¥§Çè§Üø§íâ§úì§ü®§†£§°î§§è§ßù§¨à•ÄÉ•Ö§•âº•õ™•¶™•ßª•±å¶É≠¶É∫¶Üö¶ë§¶îó¶öÄ¶ûà¶£©¶•¢¶¨ù¶Æô¶≥ì¶∫üßÉ≠ßáπßê≥ßí¨ßôäß©®ßØÅß±äß≥±®Å≥®Ñ≠ÔøΩ®ùß®•ª®¨Ä®≠§®∫Ö©É∫©ã¥©åñ©ìÜ©òã©°ß©§∑©©µ©∫ü™É∂™Ö∫™à±™ëª™ú≠™µï™πç´ãá´åà´ëÉ´óØ´õ∫´Æñ´∏™´Ωê´Ω≤¨Äò¨Çî¨Öå¨áº¨ã¢¨ëü¨î®¨•Ω¨´∫¨¨¢¨≠§¨µà¨ªë¨ªò¨ªû¨ª•≠Åê≠Ñ©≠Ü¥ÔøΩÔøΩ≠èë≠èí≠í≠≠î•≠ñÄ≠ñ≤≠óÉ≠ö°≠ú§≠•ü≠¨ç≠¨¢≠≠ß≠Æ¥≠±É≠±é≠±ê≠±Ω≠≤û≠≤∞≠µÑÆÖèÆåßÆçáÆé≥ÆíÆÆì¢ÆóôÆöäÆ°≠Æ¨ÅÆ≠πØ†ÇØ†ùÔøΩØ¢ÉØ£ÇØ•î∞Öú∞í•∞ôå∞ú¨∞®á∞≤û∞≥û∞∑æ∞ªÆ±àÑ
[I 220710 00:27:44 He2Zi:105] useless:38 dfnhe0sci6oy271pbmvquk93x84l5ztÔøΩwagrj„ÉÅ
[I 220710 00:27:44 He2Zi:128] HeZi:94180 Base:1717
[I 220710 00:27:44 He2Zi:129]  useless: 38 jzceifb6n21u98a4q3t07lpyxgomvh„ÉÅdswrkÔøΩ5
[I 220710 00:27:44 He2Zi:131] JiZi:1755  diff:0
[I 220710 00:27:44 He2Zi:147] HeZi build success -> C:/data/languages/global\HeZi.txt  C:/data/languages/global\JiZi.txt
[I 220710 00:27:44 ZiCutter:105] C:/data/languages/global\JiZi.txt load  JiZi:1719
[I 220710 00:27:45 ZiCutter:55]   C:/data/languages/global\HeZi.txt JiZi:3727 --> loadHeZi 92463  values:1041
[I 220710 00:27:45 ZiCutter:109] C:/data/languages/global\HeZi.txt HeZi:92463 values:1041
[I 220710 00:27:45 ZiCutter:112] C:/data/languages/global loaded vocab:3727
[I 220710 00:27:45 ZiCutter:105] C:/data/languages/global\JiZi.txt load  JiZi:1719
[I 220710 00:27:45 ZiCutter:55]   C:/data/languages/global\HeZi.txt JiZi:3727 --> loadHeZi 92463  values:1041
[I 220710 00:27:45 ZiCutter:109] C:/data/languages/global\HeZi.txt HeZi:92463 values:1041
[I 220710 00:27:45 ZiCutter:112] C:/data/languages/global loaded vocab:3727
['##co', '15', '##ap', 'he', '„Äá', '##sq', 'ed', '##le', 'et', '##th', 'ai', '##th', 'u', '##th', 'en', '##th', 'an', '##th', 'a', '##th', 'an', '##th', 'at', '##th', 'ek', '##th', 'an', '##th', 'i', '##th', 'ng', '##th', 'ii', '##th', 'ae', '##th', 'ao', '##th', 'ek', '##th', 'gu', '##th', 'gu', '##th', 'aa', '##th', 'nu', '##th', 'e', '##th', 'ma', '##th', 'ee', '##th', 'ek', '##th', 'ng', '##th', 'ai', '##th', 'ua', '##th', 'ai', '##th', 'a', '##th', 'at', '##th', 'ii', '##th', 'i', '##th', 'at', '##th', 'ee', '##th', 'hu', '##th', 'it', '##th', 'ue', '##ri', 'et', '##ro', 'ht', 'p', 'a', 'y', 's', '##hy', 'us', 'g', '##le', 'et', 'r', 'a', 'n', '##ri', 'et', 'd', 
'##hy', 'us', 'b', 'l', 'a', 'n', 'c', '##hy', 'us', '##la', 'te', 'l', 'e', 'v', '##la', 'te', '##sp', 'ce', '##ri', 'rk', '##sp', 'ce', '##le', 'is', 'ÁôΩ', 'È´ò', 'Â§ß', '‚ø±', '‰∏Ä', 'Â§ä', '‚ø¥', 'Âõó', 'Êàñ', '##ri', 'is', '##gr', 'ce', '‚ø∞', 'ÁÅ´', 'È´ò', '##ap', 'he', '##cc', '00', '0', '0', '‚ø∞', 'Ë®Ä', 'Ëá≥']
"""
